---
title: "LLM Use in Medical School Applications"
author: "Nick Spies, MD"
format: html
editor: visual
---

```{r}

library(tidyverse)
library(knitr)
library(httr)

controls <- 
  bind_rows(
    readxl::read_xlsx("../data/Positive controls.xlsx") |> mutate(year = "Positive Controls"),
    readxl::read_xlsx("../data/Negative_controls_personal_essays.xlsx") |> mutate(year = "Negative Controls")
  ) |> janitor::clean_names()

controls_already_run <- readRDS("../results/controls_with_gptzero_preds_combined.rds")

controls_not_run <- 
  controls |> 
    left_join(controls_already_run) |> 
    filter(is.na(Prediction))

controls_to_run <- controls_not_run |> filter(model == "ChatGPT 3.5") |> group_by(year) |> slice_sample(n = 5)

```

## Make API Inputs

```{r}

### Add a column for the length of the text
controls_sanitized <- 
  controls_to_run |> 
    rowwise() |> 
    mutate(string_length = str_length(text), 
           sanitized_inputs = str_replace_all(text, '"\\n|\t|\n|\r|\\t|\\r|\\"|\\(|\\)|\\!|\\|\\\'"', " "),
           sanitized_inputs = str_replace_all(sanitized_inputs, "\\'", ""), 
           sanitized_inputs = gsub("\\\\", "", sanitized_inputs))

### Make first 2500 characters of text a new column called "API inputs"
controls_sanitized <- controls_sanitized |> mutate(api_inputs = paste0("{\n  \"document\": \"", str_sub(sanitized_inputs, 1, max(string_length, 1000)), '",\n  \"version\": \"2024-01-09\",\n  \"multilingual\": false\n}'))

```

### Make API Calls

```{r}

### Make API calls
library(httr)

url <- "https://api.gptzero.me/v2/predict/text"
payload <- 
encode <- "json"

responses <- 
  map(controls_sanitized$api_inputs, 
    ~ VERB("POST", url, body = .x[[1]], add_headers('x-api-key' = gpt_zero_api_key), content_type("application/json"), accept("application/json"), encode = encode))

```
### Parse JSON Output from API

```{r} 

parsed_outputs <- map(responses, ~jsonlite::fromJSON(content(.x, "text")))

controls_with_gptzero_preds <- 
  controls_sanitized |> 
    ungroup() |>
    mutate(
      api_output = responses, 
      parsed_output = parsed_outputs, 
      document_output = parsed_outputs |> map("documents"), 
      Prediction = parsed_output |> map("documents") |> map("predicted_class"),
      `Probability Human` = parsed_output |> map("documents") |> map("class_probabilities") |> map("human"),
      `Probability AI` = parsed_output |> map("documents") |> map("class_probabilities") |> map("ai"),
      `Probability Mixed` = parsed_output |> map("documents") |> map("class_probabilities") |> map("mixed"),
      Confidence = parsed_output |> map("documents") |> map("confidence_score"),
      Burstiness = parsed_output |> map("documents") |> map("overall_burstiness"),
      across(Prediction:Burstiness, ~unlist(.)), 
      across(c(year, essay_type, Prediction), ~factor(.))) 

```

### Combine With Previously Run Text

```{r}

controls_with_gpt_zero_preds_combined <- bind_rows(controls_already_run, controls_with_gptzero_preds)

controls_with_gpt_zero_preds_combined |> saveRDS("../results/controls_with_gptzero_preds_combined.rds")

```

### Make Comparison Table

```{r}

library(gtsummary)

controls_with_gpt_zero_preds_combined |> 
  mutate(model = ifelse(is.na(model), "Negative Control", model)) |>
  distinct(amcas_id, year, model, Prediction, `Probability AI`, `Probability Human`, Confidence, Burstiness) |>
  select(-amcas_id, -year) |>
  tbl_summary(by = model, missing = "no", type = list(Prediction ~ "categorical", `Probability AI` ~ "continuous", `Probability Human` ~ "continuous", Confidence ~ "continuous", Burstiness ~ "continuous")) |> 
    add_p() |>
    add_q() |>
    add_ci(method = list(all_continuous() ~ "wilcox.test")) |> 
    bold_p(q = T) |> 
    bold_labels() |>
    italicize_levels()



```

### Plot Predicted Probs by Year
```{r}

gg_predicted_probs_by_year <- 
  controls_with_gpt_zero_preds_combined |> 
    ggplot(aes(x = `Probability AI`, color = year, alpha = essay_type)) + 
    stat_ecdf(linewidth = 1.5)
gg_predicted_probs_by_year

```
