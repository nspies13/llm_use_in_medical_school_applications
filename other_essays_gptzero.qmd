---
title: "LLM Use in Medical School Applications"
author: "Nick Spies, MD"
format: html
editor: visual
---

```{r}

library(tidyverse)
library(knitr)
library(httr)

essays <- 
  bind_rows(
    readxl::read_xlsx("../data/2023-2024 Failure Essay.xlsx") |> mutate(year = "2024"),
    readxl::read_xlsx("../data/2021-2022 Failure Essay.xlsx") |> mutate(year = "2022"),
    readxl::read_xlsx("../data/2023-2024 Anything Else.xlsx") |> mutate(year = "2024"),
    readxl::read_xlsx("../data/2021-2022 Anything Else.xlsx") |> mutate(year = "2022")
  ) |> janitor::clean_names()

essays_already_run <- readRDS("../results/essays_with_gptzero_preds_combined.rds")

essays_not_run <- 
  essays |> 
    left_join(essays_already_run) |> 
    filter(is.na(Prediction))

essays_to_run <- essays_not_run |> group_by(year, essay_type) |> slice_head(n = 900)

```

## Make API Inputs

```{r}

### Add a column for the length of the text
essays_sanitized <- 
  essays_to_run |> 
    rowwise() |> 
    mutate(string_length = str_length(text), 
           sanitized_inputs = str_replace_all(text, '"\\n|\t|\n|\r|\\t|\\r|\\"|\\(|\\)|\\!|\\|\\\'"', " "),
           sanitized_inputs = str_replace_all(sanitized_inputs, "\\'", ""), 
           sanitized_inputs = gsub("\\\\", "", sanitized_inputs))

### Make first 2500 characters of text a new column called "API inputs"
essays_sanitized <- essays_sanitized |> mutate(api_inputs = paste0("{\n  \"document\": \"", str_sub(sanitized_inputs, 1, max(string_length, 500)), '",\n  \"version\": \"2024-01-09\",\n  \"multilingual\": false\n}'))

```

### Make API Calls

```{r}

### Make API calls
library(httr)

url <- "https://api.gptzero.me/v2/predict/text"
payload <- 
encode <- "json"

responses <- 
  map(essays_sanitized$api_inputs, 
    ~ VERB("POST", url, body = .x[[1]], add_headers('x-api-key' = gpt_zero_api_key), content_type("application/json"), accept("application/json"), encode = encode))

```

### Parse JSON Output from API

```{r}

parsed_outputs <- map(responses, ~jsonlite::fromJSON(content(.x, "text")))

essays_with_gptzero_preds <- 
  essays_sanitized |> 
    ungroup() |>
    mutate(
      api_output = responses, 
      parsed_output = parsed_outputs, 
      document_output = parsed_outputs |> map("documents"), 
      Prediction = parsed_output |> map("documents") |> map("predicted_class"),
      `Probability Human` = parsed_output |> map("documents") |> map("class_probabilities") |> map("human"),
      `Probability AI` = parsed_output |> map("documents") |> map("class_probabilities") |> map("ai"),
      `Probability Mixed` = parsed_output |> map("documents") |> map("class_probabilities") |> map("mixed"),
      Confidence = parsed_output |> map("documents") |> map("confidence_score"),
      Burstiness = parsed_output |> map("documents") |> map("overall_burstiness"),
      across(Prediction:Burstiness, ~unlist(.)), 
      across(c(year, essay_type, Prediction), ~factor(.))) 

```

### Combine With Previously Run Text

```{r}

essays_with_gpt_zero_preds_combined <- bind_rows(essays_already_run, essays_with_gptzero_preds)

essays_with_gpt_zero_preds_combined |> saveRDS("../results/essays_with_gptzero_preds_combined.rds")

```

### Make Comparison Table

```{r}

library(gtsummary)

essays_with_gpt_zero_preds_combined |> 
  distinct(amcas_id, year, Prediction, `Probability AI`, `Probability Human`, Confidence, Burstiness) |>
  select(-amcas_id) |>
  tbl_summary(by = year, missing = "no") |> 
    add_p() |>
    add_q() |>
    add_ci(method = list(all_continuous() ~ "wilcox.test")) |> 
    bold_p(q = T) |> 
    bold_labels() |>
    italicize_levels()



```

### Plot Predicted Probs by Year

```{r}

gg_predicted_probs_by_year <- 
  essays_with_gpt_zero_preds_combined |> 
    ggplot(aes(x = `Probability AI`, color = year, alpha = essay_type)) + 
    stat_ecdf(linewidth = 1.5)
gg_predicted_probs_by_year

```
